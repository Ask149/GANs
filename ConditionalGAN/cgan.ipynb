{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "CyCXOddDi-7O",
        "colab_type": "code",
        "outputId": "0d9baab4-591d-4191-9585-2598f610f04b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "ddn_lbDul0oh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0X-S6hkeyUdj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2757
        },
        "outputId": "435a9242-06c0-476a-f10b-c69b2947bb0d"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "mnist = input_data.read_data_sets(\"MNIST\", one_hot=True)\n",
        "\n",
        "h_dim = 128\n",
        "Z_dim = 100\n",
        "mb_size = 64\n",
        "X_dim = mnist.train.images.shape[1]\n",
        "y_dim = mnist.train.labels.shape[1]\n",
        "\n",
        "\n",
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    xavier_stddev = 1./tf.sqrt(in_dim/2.)\n",
        "    return tf.random_normal(shape=size, stddev=xavier_stddev)\n",
        "\n",
        "\n",
        "def plot(samples):\n",
        "    fig = plt.figure(figsize=(4,4))\n",
        "    gs = gridspec.GridSpec(4,4)\n",
        "    gs.update(wspace=0.05, hspace=0.05)\n",
        "    \n",
        "    for i, sample in enumerate(samples):\n",
        "        ax = plt.subplot(gs[i])\n",
        "        plt.axis('off')\n",
        "        ax.set_xticklabels([])\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_aspect('equal')\n",
        "        plt.imshow(sample.reshape(28,  28), cmap='Greys_r')\n",
        "        \n",
        "    return fig\n",
        "\n",
        "\n",
        "#desciminator\n",
        "X = tf.placeholder(tf.float32, shape=[None, 784])\n",
        "y = tf.placeholder(tf.float32, shape=[None, y_dim])\n",
        "\n",
        "D_W1 = tf.Variable(xavier_init([X_dim+y_dim, h_dim]))\n",
        "D_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
        "\n",
        "D_W2 = tf.Variable(xavier_init([h_dim, 1]))\n",
        "D_b2 = tf.Variable(tf.zeros(shape=[1]))\n",
        "\n",
        "theta_D = [D_W1, D_W2, D_b1, D_b2]\n",
        "\n",
        "\n",
        "\n",
        "def discriminator(x, y):\n",
        "    inputs = tf.concat(axis=1, values=[x, y])\n",
        "    D_h1 = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)\n",
        "    D_logit = tf.matmul(D_h1, D_W2) + D_b2\n",
        "    D_prob = tf.nn.sigmoid(D_logit)\n",
        "    return D_prob, D_logit\n",
        "\n",
        "#generator\n",
        "Z = tf.placeholder(tf.float32,shape=[None, Z_dim])\n",
        "\n",
        "G_W1 = tf.Variable(xavier_init([Z_dim+y_dim, h_dim]))\n",
        "G_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
        "\n",
        "G_W2 = tf.Variable(xavier_init([h_dim, X_dim]))\n",
        "G_b2 = tf.Variable(tf.zeros(shape=[X_dim]))\n",
        "\n",
        "theta_G = [G_W1, G_W2, G_b1, G_b2]\n",
        "\n",
        "\n",
        "def generator(z,y):\n",
        "    inputs = tf.concat(axis=1, values=[z,y])\n",
        "    \n",
        "    G_h1 = tf.nn.relu(tf.matmul(inputs, G_W1)+  G_b1)\n",
        "    G_log_prob = tf.matmul(G_h1, G_W2) + G_b2\n",
        "    G_prob = tf.nn.sigmoid(G_log_prob)\n",
        "    return G_prob\n",
        "\n",
        "def sample_Z(m,n):\n",
        "    return np.random.uniform(-1., 1., size=[m, n])\n",
        "\n",
        "\n",
        "G_sample = generator(Z, y)\n",
        "D_real, D_logit_real = discriminator(X, y)\n",
        "D_fake, D_logit_fake = discriminator(G_sample, y)\n",
        "\n",
        "\n",
        "D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_real, labels=tf.ones_like(D_logit_real)))\n",
        "D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake)))\n",
        "D_loss = D_loss_real + D_loss_fake\n",
        "\n",
        "G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.ones_like(D_logit_fake)))\n",
        "\n",
        "D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D)\n",
        "G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G)\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "if not os.path.exists('out_cgan/4/'):\n",
        "    os.makedirs('out_cgan/4/')\n",
        "    \n",
        "i = 0 \n",
        "\n",
        "for it in range(250000):\n",
        "  \n",
        "    if it%1000==0:\n",
        "        n_sample = 16\n",
        "        Z_sample = sample_Z(n_sample, Z_dim)\n",
        "        y_sample = np.zeros(shape=[n_sample, y_dim])\n",
        "        y_sample[:,4] = 1\n",
        "        \n",
        "        samples = sess.run(G_sample, feed_dict={Z:Z_sample,y:y_sample})\n",
        "        fig = plot(samples)\n",
        "        plt.savefig('out_cgan/4/{}.png'.format(str(i)), bbox_inches='tight')\n",
        "        i += 1\n",
        "        plt.close(fig)\n",
        "        \n",
        "    X_mb, y_mb = mnist.train.next_batch(mb_size)\n",
        "\n",
        "    Z_sample = sample_Z(mb_size, Z_dim) \n",
        "    _, D_loss_curr = sess.run([D_solver, D_loss], feed_dict={X: X_mb, Z: Z_sample, y:y_mb})\n",
        "    _, G_loss_curr = sess.run([G_solver, G_loss], feed_dict={Z: Z_sample, y:y_mb})\n",
        "\n",
        "    if it%1000 == 0:\n",
        "        print(\"iter: %d, G_loss:%f, D_loss:%f\"%(it, G_loss_curr, D_loss_curr))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-1d1f7a512756>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "iter: 0, G_loss:1.490482, D_loss:1.881685\n",
            "iter: 1000, G_loss:7.477503, D_loss:0.010224\n",
            "iter: 2000, G_loss:4.951366, D_loss:0.045254\n",
            "iter: 3000, G_loss:6.122126, D_loss:0.044909\n",
            "iter: 4000, G_loss:4.847188, D_loss:0.151510\n",
            "iter: 5000, G_loss:4.376318, D_loss:0.152941\n",
            "iter: 6000, G_loss:5.353756, D_loss:0.324145\n",
            "iter: 7000, G_loss:3.688177, D_loss:0.341365\n",
            "iter: 8000, G_loss:2.791537, D_loss:0.765212\n",
            "iter: 9000, G_loss:3.026166, D_loss:0.612058\n",
            "iter: 10000, G_loss:2.339811, D_loss:0.769352\n",
            "iter: 11000, G_loss:2.653200, D_loss:0.809266\n",
            "iter: 12000, G_loss:2.392892, D_loss:1.054015\n",
            "iter: 13000, G_loss:2.115424, D_loss:0.720089\n",
            "iter: 14000, G_loss:1.866560, D_loss:0.741857\n",
            "iter: 15000, G_loss:2.261296, D_loss:0.958183\n",
            "iter: 16000, G_loss:2.084616, D_loss:0.822198\n",
            "iter: 17000, G_loss:1.879820, D_loss:0.841407\n",
            "iter: 18000, G_loss:2.074408, D_loss:0.725561\n",
            "iter: 19000, G_loss:1.691185, D_loss:0.771791\n",
            "iter: 20000, G_loss:1.702583, D_loss:0.772839\n",
            "iter: 21000, G_loss:1.525224, D_loss:0.832889\n",
            "iter: 22000, G_loss:1.454282, D_loss:0.986208\n",
            "iter: 23000, G_loss:1.502054, D_loss:0.823098\n",
            "iter: 24000, G_loss:1.548313, D_loss:0.939221\n",
            "iter: 25000, G_loss:1.655815, D_loss:0.867522\n",
            "iter: 26000, G_loss:1.668233, D_loss:0.901818\n",
            "iter: 27000, G_loss:1.925406, D_loss:0.721048\n",
            "iter: 28000, G_loss:1.898706, D_loss:0.646988\n",
            "iter: 29000, G_loss:1.762914, D_loss:0.877994\n",
            "iter: 30000, G_loss:1.866944, D_loss:0.699331\n",
            "iter: 31000, G_loss:1.678313, D_loss:0.844394\n",
            "iter: 32000, G_loss:1.820877, D_loss:0.913513\n",
            "iter: 33000, G_loss:1.916463, D_loss:0.931242\n",
            "iter: 34000, G_loss:1.478379, D_loss:0.948594\n",
            "iter: 35000, G_loss:1.542211, D_loss:0.908849\n",
            "iter: 36000, G_loss:1.892721, D_loss:0.813294\n",
            "iter: 37000, G_loss:1.838238, D_loss:0.859785\n",
            "iter: 38000, G_loss:2.216585, D_loss:0.629668\n",
            "iter: 39000, G_loss:1.600821, D_loss:0.713753\n",
            "iter: 40000, G_loss:1.627805, D_loss:0.910877\n",
            "iter: 41000, G_loss:1.538154, D_loss:0.776141\n",
            "iter: 42000, G_loss:1.759949, D_loss:0.744525\n",
            "iter: 43000, G_loss:2.159957, D_loss:0.671741\n",
            "iter: 44000, G_loss:1.850338, D_loss:0.822902\n",
            "iter: 45000, G_loss:1.821262, D_loss:0.882253\n",
            "iter: 46000, G_loss:1.665703, D_loss:0.850035\n",
            "iter: 47000, G_loss:1.759059, D_loss:0.728237\n",
            "iter: 48000, G_loss:1.786153, D_loss:0.780726\n",
            "iter: 49000, G_loss:1.584407, D_loss:0.830852\n",
            "iter: 50000, G_loss:1.767173, D_loss:0.782901\n",
            "iter: 51000, G_loss:1.628977, D_loss:0.834810\n",
            "iter: 52000, G_loss:1.907974, D_loss:0.755102\n",
            "iter: 53000, G_loss:1.863780, D_loss:0.732251\n",
            "iter: 54000, G_loss:1.651886, D_loss:0.792177\n",
            "iter: 55000, G_loss:1.749186, D_loss:0.762214\n",
            "iter: 56000, G_loss:1.887241, D_loss:0.789034\n",
            "iter: 57000, G_loss:1.971395, D_loss:0.803701\n",
            "iter: 58000, G_loss:1.845704, D_loss:0.791569\n",
            "iter: 59000, G_loss:1.724997, D_loss:0.777508\n",
            "iter: 60000, G_loss:1.812286, D_loss:0.772205\n",
            "iter: 61000, G_loss:1.634969, D_loss:0.838583\n",
            "iter: 62000, G_loss:1.657426, D_loss:0.795576\n",
            "iter: 63000, G_loss:1.800539, D_loss:0.919635\n",
            "iter: 64000, G_loss:1.842394, D_loss:0.835190\n",
            "iter: 65000, G_loss:1.825107, D_loss:0.697327\n",
            "iter: 66000, G_loss:1.853459, D_loss:0.718489\n",
            "iter: 67000, G_loss:1.896297, D_loss:0.823393\n",
            "iter: 68000, G_loss:1.974509, D_loss:0.806680\n",
            "iter: 69000, G_loss:1.695605, D_loss:0.836132\n",
            "iter: 70000, G_loss:1.754656, D_loss:0.944542\n",
            "iter: 71000, G_loss:1.752686, D_loss:0.775889\n",
            "iter: 72000, G_loss:1.790073, D_loss:0.719783\n",
            "iter: 73000, G_loss:1.927741, D_loss:0.772296\n",
            "iter: 74000, G_loss:1.857459, D_loss:0.690864\n",
            "iter: 75000, G_loss:1.712472, D_loss:0.807612\n",
            "iter: 76000, G_loss:1.728296, D_loss:0.833876\n",
            "iter: 77000, G_loss:1.599299, D_loss:0.812329\n",
            "iter: 78000, G_loss:1.698836, D_loss:1.014733\n",
            "iter: 79000, G_loss:1.537987, D_loss:0.838936\n",
            "iter: 80000, G_loss:1.788628, D_loss:0.704581\n",
            "iter: 81000, G_loss:1.927400, D_loss:0.796959\n",
            "iter: 82000, G_loss:1.591067, D_loss:0.751403\n",
            "iter: 83000, G_loss:1.978405, D_loss:0.821847\n",
            "iter: 84000, G_loss:1.992721, D_loss:0.639047\n",
            "iter: 85000, G_loss:1.355888, D_loss:1.005399\n",
            "iter: 86000, G_loss:1.924047, D_loss:0.693743\n",
            "iter: 87000, G_loss:1.677097, D_loss:0.814876\n",
            "iter: 88000, G_loss:1.578212, D_loss:0.797990\n",
            "iter: 89000, G_loss:1.886616, D_loss:0.795566\n",
            "iter: 90000, G_loss:1.970432, D_loss:0.765337\n",
            "iter: 91000, G_loss:1.879451, D_loss:0.760128\n",
            "iter: 92000, G_loss:1.784406, D_loss:0.838236\n",
            "iter: 93000, G_loss:1.815115, D_loss:0.662352\n",
            "iter: 94000, G_loss:1.822207, D_loss:0.649644\n",
            "iter: 95000, G_loss:1.677574, D_loss:0.768395\n",
            "iter: 96000, G_loss:1.884543, D_loss:0.821504\n",
            "iter: 97000, G_loss:1.867438, D_loss:0.685042\n",
            "iter: 98000, G_loss:2.369064, D_loss:0.645071\n",
            "iter: 99000, G_loss:1.745151, D_loss:0.748492\n",
            "iter: 100000, G_loss:1.866715, D_loss:0.775580\n",
            "iter: 101000, G_loss:1.867394, D_loss:0.795756\n",
            "iter: 102000, G_loss:1.899837, D_loss:0.741144\n",
            "iter: 103000, G_loss:1.877812, D_loss:0.766026\n",
            "iter: 104000, G_loss:1.530398, D_loss:0.723766\n",
            "iter: 105000, G_loss:1.802234, D_loss:0.742062\n",
            "iter: 106000, G_loss:1.986664, D_loss:0.586886\n",
            "iter: 107000, G_loss:1.648950, D_loss:0.869263\n",
            "iter: 108000, G_loss:1.918027, D_loss:0.829426\n",
            "iter: 109000, G_loss:1.838648, D_loss:0.724721\n",
            "iter: 110000, G_loss:2.008366, D_loss:0.529491\n",
            "iter: 111000, G_loss:1.889253, D_loss:0.836847\n",
            "iter: 112000, G_loss:2.360085, D_loss:0.804640\n",
            "iter: 113000, G_loss:1.705677, D_loss:0.658902\n",
            "iter: 114000, G_loss:1.831857, D_loss:0.786301\n",
            "iter: 115000, G_loss:2.181416, D_loss:0.686907\n",
            "iter: 116000, G_loss:1.848366, D_loss:0.634775\n",
            "iter: 117000, G_loss:2.072527, D_loss:0.680439\n",
            "iter: 118000, G_loss:2.030970, D_loss:0.743802\n",
            "iter: 119000, G_loss:1.792693, D_loss:0.821738\n",
            "iter: 120000, G_loss:2.021345, D_loss:0.824359\n",
            "iter: 121000, G_loss:1.870841, D_loss:0.971020\n",
            "iter: 122000, G_loss:1.699179, D_loss:0.791333\n",
            "iter: 123000, G_loss:2.054742, D_loss:0.820788\n",
            "iter: 124000, G_loss:2.106537, D_loss:0.798645\n",
            "iter: 125000, G_loss:1.923582, D_loss:0.755292\n",
            "iter: 126000, G_loss:1.825459, D_loss:0.874002\n",
            "iter: 127000, G_loss:1.865068, D_loss:0.750762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MFUOtcd7jO0w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}